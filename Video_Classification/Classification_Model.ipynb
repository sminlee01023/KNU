{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e15588b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, TensorDataset, random_split\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import Counter\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torchinfo import summary\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1f49038",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MedVidNpyDataset(Dataset):\n",
    "    def __init__(self, npy_dir, json_path, label_map):\n",
    "        self.npy_dir = npy_dir\n",
    "        self.label_map = label_map\n",
    "        with open(json_path, 'r') as f:\n",
    "            label_data = json.load(f)\n",
    "        self.data = []\n",
    "        for item in label_data:\n",
    "            video_id = item['video_id']\n",
    "            label_str = item['label']\n",
    "            label = self.label_map[label_str]\n",
    "            self.data.append((video_id, label))\n",
    "    def __getitem__(self, idx):\n",
    "        video_id, label = self.data[idx]\n",
    "        npy_path = os.path.join(self.npy_dir, f'{video_id}.npy')\n",
    "        features = np.load(npy_path)\n",
    "        features = torch.tensor(features, dtype=torch.float32)  # (T, 768)\n",
    "        return features, label\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d328619f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    seed = 42\n",
    "    source_dir = '../MedVidCL'\n",
    "    npy_dir = '../VideoFeatures/MedVidCL/ViT'\n",
    "    batch_size = 8\n",
    "    num_epochs = 10\n",
    "    learning_rate = 1e-4\n",
    "    embed_dim = 768\n",
    "    num_heads = 8\n",
    "    ff_dim = 2048 \n",
    "    num_layers = 2\n",
    "    max_T = 20\n",
    "    num_classes = 3\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e67b200",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "random.seed(args.seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd6c74b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {'Medical Instructional': 0, 'Medical Non-instructional': 1, 'Non-medical': 2}\n",
    "reverse_label_map = {v: k for k, v in label_map.items()}\n",
    "\n",
    "train_dataset = MedVidNpyDataset(npy_dir='../VideoFeatures/MedVidCL/ViT/train/', json_path='../MedVidCL/train.json', label_map=label_map)\n",
    "val_dataset = MedVidNpyDataset(npy_dir='../VideoFeatures/MedVidCL/ViT/val/', json_path='../MedVidCL/val.json', label_map=label_map)\n",
    "test_dataset = MedVidNpyDataset(npy_dir='../VideoFeatures/MedVidCL/ViT/test/', json_path='../MedVidCL/test.json', label_map=label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd58d464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    features, labels = zip(*batch)\n",
    "    padded = pad_sequence(features, batch_first=True)  # (B, Tmax, 768)\n",
    "    lengths = torch.tensor([f.shape[0] for f in features])\n",
    "    return padded, torch.tensor(labels), lengths\n",
    "\n",
    "# ---------------------- Positional Encoding ----------------------\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=500):\n",
    "        super().__init__()\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-np.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:x.size(1), :].unsqueeze(0).to(x.device)\n",
    "\n",
    "# ---------------------- Transformer Block ----------------------\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, mlp_ratio=4, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.attn = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout, batch_first=True)\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "        hidden_dim = int(embed_dim * mlp_ratio)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(embed_dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, embed_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.norm1(x), x, x, need_weights=False)[0]\n",
    "        return x + self.mlp(self.norm2(x))\n",
    "\n",
    "# ---------------------- FTTransformer Model ----------------------\n",
    "class FTTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim=128, depth=4, num_heads=4, dropout=0.2, num_classes=3, max_len=500):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Linear(input_dim, embed_dim)\n",
    "        self.pos_encoder = PositionalEncoding(embed_dim, max_len=max_len)\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, embed_dim))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.blocks = nn.ModuleList([\n",
    "            TransformerBlock(embed_dim, num_heads, dropout=dropout)\n",
    "            for _ in range(depth)\n",
    "        ])\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "        self.head = nn.Linear(embed_dim, num_classes)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        B = x.size(0)\n",
    "        x = self.embed(x)\n",
    "        x = self.pos_encoder(x)\n",
    "        cls = self.cls_token.expand(B, 1, -1)\n",
    "        x = torch.cat([cls, x], dim=1)\n",
    "        x = self.dropout(x)\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        x = self.norm(x)\n",
    "        return self.head(x[:, 0])  # use CLS token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5328a583",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, device, epochs=40, lr=1e-4):\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    best_acc = 0.0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for features, labels, lengths in train_loader:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(features, lengths)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        model.eval()\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for features, labels, lengths in val_loader:\n",
    "                features, labels = features.to(device), labels.to(device)\n",
    "                outputs = model(features, lengths)\n",
    "                preds = outputs.argmax(dim=1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "        val_acc = correct / total\n",
    "        print(f\"Epoch {epoch+1} | Loss: {total_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), \"best_model.pth\")\n",
    "    model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "    return model\n",
    "\n",
    "# ---------------------- Evaluation Function ----------------------\n",
    "def evaluate_model(model, loader, device, target_names):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for features, labels, lengths in loader:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            outputs = model(features, lengths)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    print(classification_report(all_labels, all_preds, target_names=target_names, digits=4))\n",
    "\n",
    "# ---------------------- Example Usage ----------------------\n",
    "def run_pipeline():\n",
    "    label_map = {'Medical Instructional': 0, 'Medical Non-instructional': 1, 'Non-medical': 2}\n",
    "    reverse_label_map = {v: k for k, v in label_map.items()}\n",
    "    train_dataset = MedVidNpyDataset('../VideoFeatures/MedVidCL/ViT/train/', '../MedVidCL/train.json', label_map)\n",
    "    val_dataset = MedVidNpyDataset('../VideoFeatures/MedVidCL/ViT/val/', '../MedVidCL/val.json', label_map)\n",
    "    test_dataset = MedVidNpyDataset('../VideoFeatures/MedVidCL/ViT/test/', '../MedVidCL/test.json', label_map)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=collate_fn)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=16, collate_fn=collate_fn)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=16, collate_fn=collate_fn)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = FTTransformer(input_dim=768, embed_dim=128, depth=4, num_heads=4, dropout=0.2, num_classes=3)\n",
    "    model = train_model(model, train_loader, val_loader, device)\n",
    "    target_names = [reverse_label_map[i] for i in range(len(reverse_label_map))]\n",
    "    evaluate_model(model, test_loader, device, target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1a7a74e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 150.9092 | Val Acc: 0.7900\n",
      "Epoch 2 | Loss: 95.6015 | Val Acc: 0.8167\n",
      "Epoch 3 | Loss: 89.2646 | Val Acc: 0.7733\n",
      "Epoch 4 | Loss: 88.3634 | Val Acc: 0.8200\n",
      "Epoch 5 | Loss: 80.6524 | Val Acc: 0.7833\n",
      "Epoch 6 | Loss: 78.6010 | Val Acc: 0.8367\n",
      "Epoch 7 | Loss: 77.1263 | Val Acc: 0.8233\n",
      "Epoch 8 | Loss: 72.6230 | Val Acc: 0.8367\n",
      "Epoch 9 | Loss: 71.8934 | Val Acc: 0.8333\n",
      "Epoch 10 | Loss: 69.1182 | Val Acc: 0.8133\n",
      "Epoch 11 | Loss: 67.3306 | Val Acc: 0.8067\n",
      "Epoch 12 | Loss: 65.1314 | Val Acc: 0.8133\n",
      "Epoch 13 | Loss: 63.0813 | Val Acc: 0.8300\n",
      "Epoch 14 | Loss: 62.1159 | Val Acc: 0.7967\n",
      "Epoch 15 | Loss: 59.0107 | Val Acc: 0.8267\n",
      "Epoch 16 | Loss: 59.3925 | Val Acc: 0.8000\n",
      "Epoch 17 | Loss: 55.0579 | Val Acc: 0.8200\n",
      "Epoch 18 | Loss: 52.4115 | Val Acc: 0.8000\n",
      "Epoch 19 | Loss: 52.9976 | Val Acc: 0.8133\n",
      "Epoch 20 | Loss: 51.8933 | Val Acc: 0.8033\n",
      "Epoch 21 | Loss: 50.6187 | Val Acc: 0.8100\n",
      "Epoch 22 | Loss: 49.8881 | Val Acc: 0.8067\n",
      "Epoch 23 | Loss: 48.0079 | Val Acc: 0.7833\n",
      "Epoch 24 | Loss: 47.0796 | Val Acc: 0.7967\n",
      "Epoch 25 | Loss: 44.6682 | Val Acc: 0.8033\n",
      "Epoch 26 | Loss: 45.5722 | Val Acc: 0.8100\n",
      "Epoch 27 | Loss: 45.0948 | Val Acc: 0.7900\n",
      "Epoch 28 | Loss: 42.2490 | Val Acc: 0.7967\n",
      "Epoch 29 | Loss: 41.1316 | Val Acc: 0.7700\n",
      "Epoch 30 | Loss: 38.6277 | Val Acc: 0.7933\n",
      "Epoch 31 | Loss: 38.4704 | Val Acc: 0.7800\n",
      "Epoch 32 | Loss: 35.1966 | Val Acc: 0.7800\n",
      "Epoch 33 | Loss: 38.0651 | Val Acc: 0.8033\n",
      "Epoch 34 | Loss: 33.3005 | Val Acc: 0.7867\n",
      "Epoch 35 | Loss: 34.4826 | Val Acc: 0.7667\n",
      "Epoch 36 | Loss: 33.9997 | Val Acc: 0.7800\n",
      "Epoch 37 | Loss: 32.3494 | Val Acc: 0.7867\n",
      "Epoch 38 | Loss: 31.6056 | Val Acc: 0.7933\n",
      "Epoch 39 | Loss: 29.1571 | Val Acc: 0.7967\n",
      "Epoch 40 | Loss: 28.4420 | Val Acc: 0.7967\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "    Medical Instructional     0.9298    0.7283    0.8168       600\n",
      "Medical Non-instructional     0.7652    0.9320    0.8404       500\n",
      "              Non-medical     0.8637    0.9000    0.8815       500\n",
      "\n",
      "                 accuracy                         0.8456      1600\n",
      "                macro avg     0.8529    0.8534    0.8462      1600\n",
      "             weighted avg     0.8577    0.8456    0.8444      1600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0951a52a",
   "metadata": {},
   "source": [
    "### ablation study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8498100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running ablation: Original ===\n",
      "Epoch 1 | Loss: 164.5487 | Val Acc: 0.7833\n",
      "Epoch 2 | Loss: 96.8387 | Val Acc: 0.7667\n",
      "Epoch 3 | Loss: 88.7873 | Val Acc: 0.8167\n",
      "Epoch 4 | Loss: 85.2697 | Val Acc: 0.7800\n",
      "Epoch 5 | Loss: 80.9070 | Val Acc: 0.8200\n",
      "Epoch 6 | Loss: 77.1699 | Val Acc: 0.8100\n",
      "Epoch 7 | Loss: 75.4817 | Val Acc: 0.8233\n",
      "Epoch 8 | Loss: 73.5645 | Val Acc: 0.8267\n",
      "Epoch 9 | Loss: 69.4273 | Val Acc: 0.8233\n",
      "Epoch 10 | Loss: 68.1826 | Val Acc: 0.8267\n",
      "Epoch 11 | Loss: 64.7166 | Val Acc: 0.8300\n",
      "Epoch 12 | Loss: 66.0535 | Val Acc: 0.8000\n",
      "Epoch 13 | Loss: 60.4093 | Val Acc: 0.8333\n",
      "Epoch 14 | Loss: 60.1501 | Val Acc: 0.8433\n",
      "Epoch 15 | Loss: 59.7575 | Val Acc: 0.8267\n",
      "Epoch 16 | Loss: 57.9551 | Val Acc: 0.8467\n",
      "Epoch 17 | Loss: 54.8884 | Val Acc: 0.8000\n",
      "Epoch 18 | Loss: 53.3789 | Val Acc: 0.8467\n",
      "Epoch 19 | Loss: 50.6114 | Val Acc: 0.8367\n",
      "Epoch 20 | Loss: 50.3679 | Val Acc: 0.8133\n",
      "Epoch 21 | Loss: 49.9425 | Val Acc: 0.8300\n",
      "Epoch 22 | Loss: 46.5220 | Val Acc: 0.8200\n",
      "Epoch 23 | Loss: 47.9519 | Val Acc: 0.8200\n",
      "Epoch 24 | Loss: 45.9413 | Val Acc: 0.8000\n",
      "Epoch 25 | Loss: 44.2574 | Val Acc: 0.8133\n",
      "Epoch 26 | Loss: 43.2200 | Val Acc: 0.7933\n",
      "Epoch 27 | Loss: 42.8015 | Val Acc: 0.7833\n",
      "Epoch 28 | Loss: 42.2760 | Val Acc: 0.8233\n",
      "Epoch 29 | Loss: 39.9170 | Val Acc: 0.7900\n",
      "Epoch 30 | Loss: 38.9386 | Val Acc: 0.8000\n",
      "Epoch 31 | Loss: 36.1809 | Val Acc: 0.8000\n",
      "Epoch 32 | Loss: 35.1496 | Val Acc: 0.7833\n",
      "Epoch 33 | Loss: 33.6135 | Val Acc: 0.7633\n",
      "Epoch 34 | Loss: 34.5301 | Val Acc: 0.7800\n",
      "Epoch 35 | Loss: 31.0946 | Val Acc: 0.7867\n",
      "Epoch 36 | Loss: 31.6322 | Val Acc: 0.7933\n",
      "Epoch 37 | Loss: 31.3949 | Val Acc: 0.7733\n",
      "Epoch 38 | Loss: 29.4369 | Val Acc: 0.7933\n",
      "Epoch 39 | Loss: 28.8330 | Val Acc: 0.7733\n",
      "Epoch 40 | Loss: 27.7311 | Val Acc: 0.7700\n",
      "\n",
      "Results for Original:\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "    Medical Instructional     0.9239    0.7083    0.8019       600\n",
      "Medical Non-instructional     0.7732    0.8660    0.8170       500\n",
      "              Non-medical     0.7914    0.9180    0.8500       500\n",
      "\n",
      "                 accuracy                         0.8231      1600\n",
      "                macro avg     0.8295    0.8308    0.8230      1600\n",
      "             weighted avg     0.8354    0.8231    0.8216      1600\n",
      "\n",
      "\n",
      "=== Running ablation: No_Positional_Encoding ===\n",
      "Epoch 1 | Loss: 125.3692 | Val Acc: 0.7833\n",
      "Epoch 2 | Loss: 89.2171 | Val Acc: 0.7933\n",
      "Epoch 3 | Loss: 81.2193 | Val Acc: 0.7767\n",
      "Epoch 4 | Loss: 75.2298 | Val Acc: 0.8167\n",
      "Epoch 5 | Loss: 69.6238 | Val Acc: 0.8167\n",
      "Epoch 6 | Loss: 62.6323 | Val Acc: 0.8133\n",
      "Epoch 7 | Loss: 57.7388 | Val Acc: 0.7900\n",
      "Epoch 8 | Loss: 53.2482 | Val Acc: 0.7900\n",
      "Epoch 9 | Loss: 49.8627 | Val Acc: 0.8067\n",
      "Epoch 10 | Loss: 46.9582 | Val Acc: 0.8100\n",
      "Epoch 11 | Loss: 42.1723 | Val Acc: 0.7733\n",
      "Epoch 12 | Loss: 35.2522 | Val Acc: 0.8300\n",
      "Epoch 13 | Loss: 31.4046 | Val Acc: 0.7367\n",
      "Epoch 14 | Loss: 32.0837 | Val Acc: 0.7733\n",
      "Epoch 15 | Loss: 28.4493 | Val Acc: 0.7133\n",
      "Epoch 16 | Loss: 26.6844 | Val Acc: 0.7633\n",
      "Epoch 17 | Loss: 19.7645 | Val Acc: 0.7633\n",
      "Epoch 18 | Loss: 20.4571 | Val Acc: 0.7867\n",
      "Epoch 19 | Loss: 21.7401 | Val Acc: 0.7300\n",
      "Epoch 20 | Loss: 14.0705 | Val Acc: 0.7833\n",
      "Epoch 21 | Loss: 16.3040 | Val Acc: 0.7267\n",
      "Epoch 22 | Loss: 16.6099 | Val Acc: 0.7500\n",
      "Epoch 23 | Loss: 13.9271 | Val Acc: 0.7700\n",
      "Epoch 24 | Loss: 12.4859 | Val Acc: 0.7700\n",
      "Epoch 25 | Loss: 12.3693 | Val Acc: 0.8100\n",
      "Epoch 26 | Loss: 13.8234 | Val Acc: 0.7833\n",
      "Epoch 27 | Loss: 11.4646 | Val Acc: 0.7867\n",
      "Epoch 28 | Loss: 6.2547 | Val Acc: 0.7867\n",
      "Epoch 29 | Loss: 13.3130 | Val Acc: 0.7700\n",
      "Epoch 30 | Loss: 9.5577 | Val Acc: 0.8067\n",
      "Epoch 31 | Loss: 6.8983 | Val Acc: 0.7733\n",
      "Epoch 32 | Loss: 7.5994 | Val Acc: 0.7967\n",
      "Epoch 33 | Loss: 6.9215 | Val Acc: 0.7333\n",
      "Epoch 34 | Loss: 8.3764 | Val Acc: 0.7833\n",
      "Epoch 35 | Loss: 5.1205 | Val Acc: 0.8233\n",
      "Epoch 36 | Loss: 5.0635 | Val Acc: 0.7867\n",
      "Epoch 37 | Loss: 3.2363 | Val Acc: 0.7867\n",
      "Epoch 38 | Loss: 8.4726 | Val Acc: 0.7800\n",
      "Epoch 39 | Loss: 8.9847 | Val Acc: 0.7933\n",
      "Epoch 40 | Loss: 3.3007 | Val Acc: 0.7833\n",
      "\n",
      "Results for No_Positional_Encoding:\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "    Medical Instructional     0.9025    0.6633    0.7646       600\n",
      "Medical Non-instructional     0.7063    0.8900    0.7876       500\n",
      "              Non-medical     0.8374    0.8860    0.8610       500\n",
      "\n",
      "                 accuracy                         0.8037      1600\n",
      "                macro avg     0.8154    0.8131    0.8044      1600\n",
      "             weighted avg     0.8209    0.8037    0.8019      1600\n",
      "\n",
      "\n",
      "=== Running ablation: No_CLS_Token ===\n",
      "Epoch 1 | Loss: 143.3560 | Val Acc: 0.7467\n",
      "Epoch 2 | Loss: 94.6158 | Val Acc: 0.8233\n",
      "Epoch 3 | Loss: 91.1532 | Val Acc: 0.8200\n",
      "Epoch 4 | Loss: 84.5104 | Val Acc: 0.8200\n",
      "Epoch 5 | Loss: 81.1530 | Val Acc: 0.8367\n",
      "Epoch 6 | Loss: 77.7138 | Val Acc: 0.8400\n",
      "Epoch 7 | Loss: 76.1318 | Val Acc: 0.8067\n",
      "Epoch 8 | Loss: 71.9011 | Val Acc: 0.8167\n",
      "Epoch 9 | Loss: 70.1405 | Val Acc: 0.8200\n",
      "Epoch 10 | Loss: 67.0342 | Val Acc: 0.8233\n",
      "Epoch 11 | Loss: 65.6134 | Val Acc: 0.8367\n",
      "Epoch 12 | Loss: 63.7370 | Val Acc: 0.8233\n",
      "Epoch 13 | Loss: 63.0516 | Val Acc: 0.8000\n",
      "Epoch 14 | Loss: 61.7365 | Val Acc: 0.8233\n",
      "Epoch 15 | Loss: 56.1327 | Val Acc: 0.8233\n",
      "Epoch 16 | Loss: 55.6463 | Val Acc: 0.8233\n",
      "Epoch 17 | Loss: 53.8458 | Val Acc: 0.7933\n",
      "Epoch 18 | Loss: 53.9028 | Val Acc: 0.8233\n",
      "Epoch 19 | Loss: 51.2595 | Val Acc: 0.8067\n",
      "Epoch 20 | Loss: 49.3190 | Val Acc: 0.8100\n",
      "Epoch 21 | Loss: 50.4443 | Val Acc: 0.8133\n",
      "Epoch 22 | Loss: 48.6319 | Val Acc: 0.8067\n",
      "Epoch 23 | Loss: 43.3594 | Val Acc: 0.8167\n",
      "Epoch 24 | Loss: 42.7290 | Val Acc: 0.8100\n",
      "Epoch 25 | Loss: 43.3890 | Val Acc: 0.8267\n",
      "Epoch 26 | Loss: 41.1083 | Val Acc: 0.8067\n",
      "Epoch 27 | Loss: 42.1209 | Val Acc: 0.8133\n",
      "Epoch 28 | Loss: 39.5635 | Val Acc: 0.7800\n",
      "Epoch 29 | Loss: 37.4855 | Val Acc: 0.7933\n",
      "Epoch 30 | Loss: 37.4923 | Val Acc: 0.8133\n",
      "Epoch 31 | Loss: 35.1752 | Val Acc: 0.8233\n",
      "Epoch 32 | Loss: 33.6715 | Val Acc: 0.7900\n",
      "Epoch 33 | Loss: 33.7524 | Val Acc: 0.7967\n",
      "Epoch 34 | Loss: 30.8176 | Val Acc: 0.8000\n",
      "Epoch 35 | Loss: 29.7919 | Val Acc: 0.7867\n",
      "Epoch 36 | Loss: 26.0096 | Val Acc: 0.7833\n",
      "Epoch 37 | Loss: 24.9237 | Val Acc: 0.7700\n",
      "Epoch 38 | Loss: 28.5579 | Val Acc: 0.7867\n",
      "Epoch 39 | Loss: 24.1858 | Val Acc: 0.7967\n",
      "Epoch 40 | Loss: 23.7883 | Val Acc: 0.7800\n",
      "\n",
      "Results for No_CLS_Token:\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "    Medical Instructional     0.9128    0.7500    0.8234       600\n",
      "Medical Non-instructional     0.8060    0.8640    0.8340       500\n",
      "              Non-medical     0.8126    0.9280    0.8665       500\n",
      "\n",
      "                 accuracy                         0.8413      1600\n",
      "                macro avg     0.8438    0.8473    0.8413      1600\n",
      "             weighted avg     0.8481    0.8413    0.8402      1600\n",
      "\n",
      "\n",
      "===== Ablation Study Summary =====\n",
      "Original - Accuracy: 0.8231, F1: 0.8230\n",
      "No_Positional_Encoding - Accuracy: 0.8037, F1: 0.8044\n",
      "No_CLS_Token - Accuracy: 0.8413, F1: 0.8413\n"
     ]
    }
   ],
   "source": [
    "# 1. Without Positional Encoding\n",
    "class FTTransformerNoPosEnc(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim=128, depth=4, num_heads=4, dropout=0.2, num_classes=3, max_len=500):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Linear(input_dim, embed_dim)\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, embed_dim))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.blocks = nn.ModuleList([\n",
    "            TransformerBlock(embed_dim, num_heads, dropout=dropout)\n",
    "            for _ in range(depth)\n",
    "        ])\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "        self.head = nn.Linear(embed_dim, num_classes)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        B = x.size(0)\n",
    "        x = self.embed(x)\n",
    "        # Positional encoding removed\n",
    "        cls = self.cls_token.expand(B, 1, -1)\n",
    "        x = torch.cat([cls, x], dim=1)\n",
    "        x = self.dropout(x)\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        x = self.norm(x)\n",
    "        return self.head(x[:, 0])\n",
    "\n",
    "# 2. Without CLS Token (using mean pooling)\n",
    "class FTTransformerNoCLS(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim=128, depth=4, num_heads=4, dropout=0.2, num_classes=3, max_len=500):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Linear(input_dim, embed_dim)\n",
    "        self.pos_encoder = PositionalEncoding(embed_dim, max_len=max_len)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.blocks = nn.ModuleList([\n",
    "            TransformerBlock(embed_dim, num_heads, dropout=dropout)\n",
    "            for _ in range(depth)\n",
    "        ])\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "        self.head = nn.Linear(embed_dim, num_classes)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        x = self.embed(x)\n",
    "        x = self.pos_encoder(x)\n",
    "        x = self.dropout(x)\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        x = self.norm(x)\n",
    "        # Mean pooling instead of CLS token\n",
    "        return self.head(x.mean(dim=1))\n",
    "\n",
    "# Ablation Study Runner\n",
    "def run_ablation_study(train_loader, val_loader, test_loader, device):\n",
    "    ablations = {\n",
    "        \"Original\": FTTransformer(input_dim=768, num_classes=3),\n",
    "        \"No_Positional_Encoding\": FTTransformerNoPosEnc(input_dim=768, num_classes=3),\n",
    "        \"No_CLS_Token\": FTTransformerNoCLS(input_dim=768, num_classes=3)\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    target_names = [reverse_label_map[i] for i in range(3)]\n",
    "    \n",
    "    for name, model in ablations.items():\n",
    "        print(f\"\\n=== Running ablation: {name} ===\")\n",
    "        trained_model = train_model(model, train_loader, val_loader, device)\n",
    "        print(f\"\\nResults for {name}:\")\n",
    "        \n",
    "        # 수정된 부분: evaluate_model 호출 방식 변경\n",
    "        all_preds, all_labels = evaluate_model(\n",
    "            trained_model, \n",
    "            test_loader, \n",
    "            device, \n",
    "            target_names, \n",
    "            return_preds_labels=True\n",
    "        )\n",
    "        \n",
    "        # 결과 리포트 생성\n",
    "        print(classification_report(all_labels, all_preds, target_names=target_names, digits=4))\n",
    "        \n",
    "        # 결과 저장\n",
    "        report = classification_report(\n",
    "            all_labels, all_preds,\n",
    "            target_names=target_names,\n",
    "            output_dict=True,\n",
    "            digits=4\n",
    "        )\n",
    "        results[name] = {\n",
    "            \"accuracy\": report[\"accuracy\"],\n",
    "            \"macro_f1\": report[\"macro avg\"][\"f1-score\"]\n",
    "        }\n",
    "    \n",
    "    # 결과 비교\n",
    "    print(\"\\n===== Ablation Study Summary =====\")\n",
    "    for name, metrics in results.items():\n",
    "        print(f\"{name} - Accuracy: {metrics['accuracy']:.4f}, F1: {metrics['macro_f1']:.4f}\")\n",
    "\n",
    "# 수정된 evaluate_model 함수\n",
    "def evaluate_model(model, loader, device, target_names, return_preds_labels=False):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for features, labels, lengths in loader:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            outputs = model(features, lengths)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    if return_preds_labels:\n",
    "        return all_preds, all_labels\n",
    "    \n",
    "    print(classification_report(all_labels, all_preds, target_names=target_names, digits=4))\n",
    "\n",
    "# Run ablation study\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize datasets and loaders\n",
    "    label_map = {'Medical Instructional': 0, 'Medical Non-instructional': 1, 'Non-medical': 2}\n",
    "    reverse_label_map = {v: k for k, v in label_map.items()}\n",
    "    \n",
    "    train_dataset = MedVidNpyDataset(npy_dir='../VideoFeatures/MedVidCL/ViT/train/', \n",
    "                                    json_path='../MedVidCL/train.json', \n",
    "                                    label_map=label_map)\n",
    "    val_dataset = MedVidNpyDataset(npy_dir='../VideoFeatures/MedVidCL/ViT/val/', \n",
    "                                  json_path='../MedVidCL/val.json', \n",
    "                                  label_map=label_map)\n",
    "    test_dataset = MedVidNpyDataset(npy_dir='../VideoFeatures/MedVidCL/ViT/test/', \n",
    "                                   json_path='../MedVidCL/test.json', \n",
    "                                   label_map=label_map)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=collate_fn)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=16, collate_fn=collate_fn)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=16, collate_fn=collate_fn)\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Run ablation study\n",
    "    run_ablation_stu  dy(train_loader, val_loader, test_loader, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70af9bb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kbri",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
